\section{Related Work}
Based on a review of published literature, the effectiveness of the variance in kinesthetic guidance has not been fully explored. 
However, there have been some publications looking into the efficacy of audio and vibrotactile feedback modalities. 
In paper \cite{PLosONE}, a study was conducted on the efficiency of implementing vibrotactile and audio feedback systems, and comparing performance to using the cane only. 
It was found that participants could complete a navigation task faster with the the additional feedback systems. 
Comparison between the two systems showed that the participants had faster response and speed with audio feedback as opposed to vibrotactile feedback. 

However, another paper (\cite{IEEE}) which compared the accuracy of performance between audio and vibrotactile feedback systems showed that although the speed of response was faster with audio systems, the accuracy and closeness to a prescribed path was better with haptic feedback. 
Although our project is not trying to approach this problem through a vibrotactile guidance system, this gives us an indication that humans are responsive to tactile guidance. 
This is also supported by the findings of \cite{autonavigation}, where the participants felt vibro-tactile feedback is important and effective. 
In this study, some of the participants thought environment noise could interfere with audio feedback, and thus were not comfortable with this style of feedback. 

Audio feedback guidance has been used frequently. 
Although it is easier to get acquaintances and learn, it does not serve people with low vision. 
Most of the tools have been aimed to serve complete visual impairments and low vision community is widely ignored. People with low vision have some capabilities to see and with the right tools, it can help them guide. 
\cite{smartglasses} designed two wayfinding guidance, audio and visual. 
Visual wayfinding guidance gives an indoor GPS like a route where actions and distance are displayed on the side of the path like a street sign while audio does a similar task through audio feedback. 
Visual wayfinding guidance results were much better than audio but all participants wanted a combination tools of visual and audio that will optimize their wayfinding experience. 
Because both were helpful in different parts of the task.  

The publication in \cite{kinestheticteaching} conducted experiments which were a direct opposite to the goals of our project. 
Their focus was on determining which was the preferred method of teaching a robot to perform a task: through kinesthetic or through teleoperation. 
However, our focus is for the robot to guide the visually-impaired user. 
They found that people prefer kinesthetic over teleoperation due to the learning curve to perform and get comfortable with teleoperation. 
The paper in \cite{humanteacher} did a similar task in teaching robot arm motion to catch a ball. 
They also provided more details about the tools they used to complete and implement their experiment. 

In \cite{robotassist}, the authors compared voice-only assistive robot and collaborative assistive robot for undertaking a task completion. 
Their findings, based on study conducted on 12 blind participants, suggested that people prefer collaborative assistance over voice only assistance.
In their study, they concluded that collaborative assistance was more effective, less time consuming, easier to work with and was socially more acceptable. 
Furthermore, some of the participants had difficulty understanding the commands from voice-only assistive robots. 